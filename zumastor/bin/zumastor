#!/bin/bash
# Zumastor Linux Storage Server
# Copyright (c) 2006 Google Inc.
# Author: Daniel Phillips <phillips@google.com>
# Licensed under the GNU GPL version 2

. /lib/zumastor/common || { echo "$0: unable to load common zumastor functions"; exit 1; }
. /lib/zumastor/ddfake

function read_and_inc {
	[ $# -eq 1 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r filename=$1
	local num

	# FIXME TODO add error 
	read num < $filename || return 1
	echo $(( num+1 )) > $filename || return 1

	echo $num

	return 0
}

# log <filename> <message>
# uses global variable pid, sets it if its not set
# allows setting pid when daemonized
function log {
	local msg=$1 file=$2

	[[ $pid == "" ]] && pid=$$
	[[ $file == "" ]]  && file=/dev/stdout

	echo "`date` $0[$pid]: $msg" >> $file
}

# new_snapshot <volume name> <kind>
#  Create a new snapshot for <volume>'s interval <kind> and rotate out old
#  snapshots as necessary.  Called from the zumastor master when triggered with
#  an interval.
function new_snapshot {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r kind=$2
	local -r master=$VOLUMES/$vol/master
	local -r sock=${SERVERS}/$vol
	local -r maxfile=$master/schedule/$kind
	local -r listfile=$master/snapshots/$kind
	local -a snapshots
	local max
	local next
	local num
	local oldest

	log "new '$kind' snapshot requested for volume '$vol'"

	[ -f $maxfile ] || { echo "$0: '$maxfile' is missing, doing nothing"; return 1; }
	read max <$maxfile
	[ $max ] || { echo "$0: '$maxfile' is empty, doing nothing"; return 1; }
	[ $max -gt 0 ] || { echo "$0: '$maxfile' contains zero, doing nothing"; return 1; }

	next=$(read_and_inc $master/next) || { log "snapshot number error: $master/next"; return 1; }
	log "new snapshot will be '$next'"

	if [ -f $listfile ]; then
		read -a snapshots <$listfile
	else
		snapshots=()
	fi
	num=${#snapshots[@]}
	snapshots[$num]=$next

	create_snapshot $vol $next
	mount_device $vol $next

	if [[ $num -ge $max ]]; then
		oldest=${snapshots[0]}

		# this will umount, remove device, and delete snapshot if it
		# is the only reference
		usecount_decrement $vol $oldest
		#umount_device $vol $oldest
		#remove_device $vol $oldest
		#ddsnap delete $sock $oldest
		unset snapshots[0]
	fi
	echo ${snapshots[@]} >$listfile
	log "'$kind' snapshot list is now: ${snapshots[@]}"
}

function send_to_fifo {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r fifo=$1
	local -r data=$2

	[[ -e $fifo ]] || { echo "$fifo does not exist"; return 1; }
	[[ -p $fifo ]] || { echo "$fifo not a fifo"; return 1; }
	[[ -w $fifo ]] || { echo "$fifo not writable"; return 1; }

	echo $data > $fifo || { echo "error writing to $fifo"; return 1; }

	return 0
}

# new_target_snapshot <volume> <hostname>
#   Create a snapshot for <volume> for the replication to target <hostname> and
#   send the new snapshot number to the target's pipe.  Called by the zumastor
#   master daemon (run_master) when triggered with "target"
function new_target_snapshot {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r hostname=$2
	local -r target_fifo=$VOLUMES/$vol/targets/$hostname/trigger
	local -r sock=${SERVERS}/$vol
	local -r master=$VOLUMES/$vol/master

	[ -e $target_fifo ] || { log "target trigger for $hostname does not exist"; return 1; }

	# create snapshot
	# write id down the trigger

	next=$(read_and_inc $master/next) || { log "ssn error: $master/next"; return 1; }

	log "new snapshot will be '$next'"

	# need to create the device in order for ddsnap delta send to work
	create_snapshot $vol $next
	# but we don't need to mount it

	send_to_fifo $target_fifo $next || return 1

}

function run_remote  {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r host=$1
	local -r command=$2

	# FIXME TODO input checking

	if [[ $host = "localhost" ]]; then
		echo $command | sh
	else
		# run "sh" to prevent "stdin: is not a tty" stderr output
		echo $command | $SSH_COMMAND $host sh
	fi
}

function usecount_increment {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r snap=$2
	local -r server=$SERVERS/$vol

	# FIXME TODO input chekcing
	ddsnap usecount $server $snap 1 || return 1
}

function usecount_decrement {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r snap=$2
	local -r server=$SERVERS/$vol
	local output
	local usecount

	# FIXME TODO input chekcing

	output=$(ddsnap usecount $server $snap -1) || return 1
	usecount=${output/*New usecount: /}

	# output was wrong, didn't find "New usecount: ", so exit with an error
	if [[ $usecount == $output ]]; then return 1; fi

	if [[ $usecount -eq 0 ]]; then
		# umount may fail if we haven't mounted the device
		# so we just ignore the error
		umount_device $vol $snap 2> /dev/null
		remove_device $vol $snap || return 1
		ddsnap delete $server $snap
	fi

	return 0
}

# replicate_snapshot
# called from target zumastor daemon (run_target)
function replicate_snapshot {
	[ $# -eq 3 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r host=$2
	local -r snap=$3
	local -r target_dir=$VOLUMES/$vol/targets/$host
	local -r send_file=$target_dir/send
	local -r hold_file=$target_dir/hold
	local -r server=$SERVERS/$vol
	local -r port_file=$target_dir/port
	local -r myhost=`hostname -s`
	local old_snap rem_snap port

	log "replication for snapshot '$snap' on volume '$vol' to '$host'"

	old_snap=$(cat $hold_file) || { echo "initial replication"; old_snap=0; }

	rem_snap=$(run_remote $host "cat $VOLUMES/$vol/source/hostname") && [[ $rem_snap = $myhost ]] || \
		{ log "set '$myhost' as source for '$vol' on '$host' first!"; usecount_decrement $vol $snap; return 1; }

	if [ -e $send_file ]; then
		log "$send_file shouldn't exist"
		return 1
	fi

	echo $snap > $send_file || { log "error writing snapshot id '$snap' to '$send_file'"; \
		rm $send_file; usecount_decrement $vol $snap; return 1; }

	port=$(cat $port_file) || { log "error reading port from '$port_file'"; \
		rm $send_file; usecount_decrement $vol $snap; return 1; }

	rem_snap=$(run_remote $host "zumastor receive $vol $port start") || \
		{ log "starting remote snapshot receive failed"; \
		rm $send_file; usecount_decrement $vol $snap; return 1; }

	log "remote snapshot id $rem_snap listen started"

	# send the changes since the last snapshot via ddsnap delta send
	ddsnap delta send -r -g 5 $server $old_snap $snap /dev/mapper/$vol $rem_snap $host:$port || { \
		log "delta send $server $old_snap $snap /dev/mapper/$vol $rem_snap $host:$port failed"; \
		rm $send_file; usecount_decrement $vol $snap; return 1; }

	run_remote $host "zumastor receive $vol $port done" || { log "zumastor receive $vol $port done failed"; \
		rm $send_file; usecount_decrement $vol $snap; return 1; }

	# !!! FIXME TODO this is racy, we should save state by journaling
	mv $send_file $hold_file

	# FIXME TODO conditional will go away once we have full volume replication
	[[ $old_snap -ne 0 ]] && usecount_decrement $vol $old_snap

	return 0
}

function run_master {
	[ $# -eq 1 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r fifo=$VOLUMES/$vol/master/trigger
	local -r log=${LOGS}/$vol/master.log
	local -r cron=${CRONS}/$vol
	local kind

	[ -r $fifo ] && [ -p $fifo ] || { echo "$0: master snapshot trigger '$fifo' is missing"; return 1; }
	touch ${CRONS}/$vol || return 1

	# daemonize (close stdin, stdout, stderr)
	#exec 0</dev/null 1>/dev/null 2>/dev/null

	mount_device $vol -1 rw

	# we reopen the log for each write so rotation works
	pid=""
	while true; do
		if [[ $pid == "" ]]; then
			pid=$!
			log "starting master snapshot daemon for volume '$vol'" $log
		fi
		# this is now overloaded to support two types of requests to create snapshots:
		# <kind> - which triggers a periodic snapshot (hourly, daily, etc)
		# target <hostname> - which triggers a snapshot for replication
		read kind hostname <$fifo || exit 1
		if [[ $kind = "target" ]]; then
			new_target_snapshot $vol $hostname >> $log 2>&1
		else
			find_in $kind ${KINDS[@]} || log "unknown snapshot type '$kind'" $log
			new_snapshot $vol $kind >> $log 2>&1
		fi
	done &
}

function run_target {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1 host=$2

	local -r fifo=$VOLUMES/$vol/targets/$host/trigger
	local -r period_file=$VOLUMES/$vol/targets/$host/period
	local -r log=${LOGS}/$vol/target-${host}.log
	local -r master_fifo=$VOLUMES/$vol/master/trigger
	local -r sleep_pid=$VOLUMES/$vol/targets/$host/.sleeppid
	local snap state period spid

	[[ -e $period_file ]] && read period < $period_file || log "no period specified" $log
	[[ -z $period ]] || [[ $period -ge 0 ]] || { log "invalid period '$period' specified" $log; return 1; }

	[ -r $fifo ] && [ -p $fifo ] || { log "target replication trigger '$fifo' is missing" $log; return 1; }

	# daemonize (close stdin, stdout, stderr)
	exec 0</dev/null 1>/dev/null 2>/dev/null

	pid=""
	while true; do
		if [[ $pid == "" ]]; then
			pid=$!
			log "start daemon volume '$vol', target '$host', period '$period'" $log
		fi
		# !!! FIXME TODO Implement skipping to most recent snapshot if there is a backlog

		log "waiting for new snapshot..." $log

		# wrap in a while loop because read will fail is ERESTARTSYS when the
		# sleeping child exits
		snap=""
		while [[ $snap == "" ]]; do
			[[ -r $fifo ]] || { log "$fifo not readable" $log; return 1; }
			read snap <$fifo
			sleep 1 # not necesary, just in case
		done

		replicate_snapshot $vol $host $snap >> $log 2>&1 &&
		if [[ $? == 0 ]]; then #success 
			log "successfully replicated snapshot $snap" $log
			[[ -z $period ]] || (
				pid=$!
				log "sleeper starting" $log
				spid=""; read spid < $sleep_pid 2> /dev/null
				[[ $spid != "" ]] && { log "killing sleeper $spid" $log; kill $spid; }
				echo $pid > $sleep_pid
				log "sleeping ${period}s for replication cycle" $log
				sleep $period
				log "sleep completed, triggering replication" $log
				echo target $host > $VOLUMES/$vol/master/trigger
				rm $sleep_pid
				exit
			) &
		else
			log "replicate error on snapshot $snap" $log
			usecount_decrement $vol $snap >> $log 2>&1
		fi
	done &
}

function stop_master {
	[ $# -eq 1 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r cron=${CRONS}/$vol

	rm -f $cron
	pkill -f "zumastor start master $vol" || return 1
}

function stop_nag {
	[ $# -eq 1 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1

	pkill -f "zumastor start source $vol" || return 1
}

function stop_target {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r host=$2

	pkill -f "zumastor start target $vol $host" || return 1
	rm $VOLUMES/$vol/targets/$host/.sleeppid 2> /dev/null
}

function init_define_volume {
	[ $# -eq 3 ] || [ $# -eq 4 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r odev=$2
	local -r sdev=$3
	local -r mdev=$4
	local -r path=$VOLUMES/$vol
	local -r sock=${SERVERS}/$vol
	local -r log=$LOGS/$vol/init.log

	read -p "All data on origin $odev will be destroyed, continue? (y/N) " -t 30 \
		|| { echo "timeout."; return 1; }

	if [[ $REPLY != "y" ]]; then return 1; fi

	mkdir $LOGS/$vol || return 1
	mkdir $path || return 1
	mkdir $path/device || return 1
	ln -sf $odev $path/device/origin  || return 1
	ln -sf $sdev $path/device/snapstore || return 1
	[ -z $mdev ] || ln -sf $mdev $path/device/meta || return 1
	mkdir $path/targets || return 1

	log "initializing volume '$vol', origindev '$odev', snapdev '$sdev'" $log
	ddsnap initialize $sdev $odev $mdev 2>>$log || { echo init failed ;  return 1 ; }

	start_volume $vol || { echo start failed ;return 1; }

	create_device $vol -1 || { echo create failed;return 1; }
	# do not mount

	log "zeroing out origin device" $log
	echo -n Zeroing out origin device. This may take a while...
	dd if=/dev/zero of=/dev/mapper/$vol bs=1M >> $log 2>&1
	echo done!
	log "zeroing out origin device completed" $log
}

function define_volume {
	[ $# -eq 3 ] || [ $# -eq 4 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r odev=$2
	local -r sdev=$3
	local -r mdev=$4
	local -r path=$VOLUMES/$vol
	local -r sock=${SERVERS}/$vol

	mkdir $LOGS/$vol || return 1
	mkdir $path || return 1
	mkdir $path/device || return 1
	ln -sf $odev $path/device/origin  || return 1
	ln -sf $sdev $path/device/snapstore || return 1
	[ -z $mdev ] || ln -sf $mdev $path/device/meta || return 1
	mkdir $path/targets || return 1

	start_volume $vol || { echo start failed ;return 1; }

	create_device $vol -1 || { echo create failed;return 1; }

	return 0
}

function forget_volume {
	[ $# -eq 1 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r path=$VOLUMES/$vol
	local -r sock=${SERVERS}/$vol
	local -r agentlog=${LOGS}/$vol/agent.log
	local -r serverlog=${LOGS}/$vol/server.log

	local id host targets

	pushd $VOLUMES/$vol/targets > /dev/null && \
	targets=`echo *` && \
	popd > /dev/null
	for host in $targets; do
		forget_target $vol $host
	done

	[ -d $VOLUMES/$vol/source ] && forget_source $vol

	forget_master $vol

	# remove any snapshots devices first, then the origin
	# FIXME racy because forget_target and forget_master just send a signal
	# to kill off the other processes taking shapshots
	for id in $(ddsnap status $sock --list); do
		umount_device $vol $id 2> /dev/null
		remove_device $vol $id
	done
	umount_device $vol -1 2> /dev/null
	remove_device $vol -1

	stop_volume $vol

	rmdir $path/targets
	rm -rf $path/device
	[[ -e $path/zero ]] && rm $path/zero

	[[ -d $LOGS/.archived ]] || mkdir $LOGS/.archived
	mv $LOGS/$vol $LOGS/.archived/`date +%s`.$vol
	rmdir $path || return 1
}

function define_target {
	[[ $# -eq 3 ]] || [[ $# -eq 4 ]] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r host=$2
	local -r port=$3
	local -r period=$4
	local -r path=$VOLUMES/$vol/targets/$host

	mkdir $path || return 1
	mkfifo $path/trigger || return 1
	echo $port > $path/port || return 1
	[[ -z $period ]] || echo $period > $path/period || return 1
	zumastor start target $vol $host || return 1
}

function forget_target {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r host=$2
	local -r path=$VOLUMES/$vol/targets/$host
	local -r holdfile=$path/hold
	local -r sendfile=$path/send
	local snap

	zumastor stop target $vol $host

	# clean up the hold snapshot
	snap=$(cat $holdfile 2> /dev/null)
	[[ $snap != "" ]] && usecount_decrement $vol $snap

	# clean up the send snapshot
	snap=$(cat $sendfile 2> /dev/null)
	[[ $snap != "" ]] && usecount_decrement $vol $snap

	rm -rf $path || return 1
}

function forget_source {
	[ $# -eq 1 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local hold

	# !!! FIXME TODO clean up replication in progress
	hold=$(cat $VOLUMES/$vol/source/hold 2> /dev/null)
	[[ $hold != "" ]] && usecount_decrement $vol $hold

	rm -rf $VOLUMES/$vol/source || return 1
	return 0
}

function set_master {
	[ $# -eq 3 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r kind=$2
	local -r count=$3
	local -r path=$VOLUMES/$vol
	local new
	local conv

	if [ -d $path/source ]; then
		read -p "$vol is currently a downstream volume, convert to master? [n] " conv
		[ X$conv = Xy ] || [ X$conv = Xyes ] || return 1

		rm -rf $path/source
	fi

	[ -d $path/master ] || new=yes

	if [ $new ]; then
		mkdir $path/master || return 1
		mkdir $path/master/schedule || return 1
	fi

	if [ $count -gt 0 ]; then
		echo $count >$path/master/schedule/$kind || return 1
	else
		rm -f $path/master/schedule/$kind
	fi

	if [ $new ]; then
		echo 1 >$path/master/next || return 1
		mkdir $path/master/snapshots || return 1
		mkfifo $path/master/trigger || return 1
		zumastor start master $vol || return 1
	fi
}

function forget_master {
	[ $# -eq 1 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r path=$VOLUMES/$vol

	stop_master $vol
	[ -d $path/master ] && rm -rf $path/master
}

function set_source {
	[[ $# -eq 2 ]] || [[ $# -eq 3 ]] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r host=$2
	local -r period=$3
	local -r path=$VOLUMES/$vol
	local conv
	local rempath
	local -r myhost=`hostname -s`
	local -r mysize=$(ddsnap status $SERVERS/$vol --size) || return 1

	if [ -d $path/master ]; then
		read -p "$vol is currently a master, convert to a downstream volume? [n] " conv
		[ X$conv = Xy ] || [ X$conv = Xyes ] || return 1

		forget_master $vol
	fi

	if [ -e $path/source/hostname ]; then
		echo "$0: already set as a downstream volume for " $(cat $path/source/hostname)
		return 1
	fi

	rempath=$VOLUMES/$vol/targets/$myhost/trigger
	conv=$(run_remote $host "ls $rempath 2>/dev/null") && [[ $conv = $rempath ]] || \
		{ echo "setup '$myhost' as target for volume '$vol' on '$host' first!"; return 1; }

	conv=$(run_remote $host "ddsnap status $SERVERS/$vol --size")

	[[ $conv -gt $mysize ]] && { echo "upstream volume ($conv) is larger than local ($mysize), cannot set source" ; return 1; }

	mkdir -p $path/source || return 1
	echo $host > $path/source/hostname || return 1
	[[ -z $period ]] || echo $period > $path/source/period || return 1

	# FIXME TODO - snapshot 0 may be used for the source for chained replication, therefore
	# we arbitrarily pick 1, because no other snapshots should exist
	create_snapshot $vol 1 || return 1
	echo 1 > $path/source/hold || return 1
}

function trigger_snapshot {
	[ $# -eq 2 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r kind=$2
	local -r fifo=$VOLUMES/$vol/master/trigger

	send_to_fifo $fifo $kind || return 1
}

function trigger_replication {
	[[ $# -eq 2 ]] || [[ $# -eq 3 ]] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r host=$2
	local snap=$3
	local -r target_fifo=$VOLUMES/$vol/targets/$host/trigger
	local -r master_fifo=$VOLUMES/$vol/master/trigger


	if [[ -z $snap ]]; then
		# no snapshot specified, asking the master for a new one
		send_to_fifo $master_fifo "target $host" || return 1
	else
		# increase reference count to pin snapshot
		usecount_increment $vol $snap
		# send specified snapshot
		send_to_fifo $fifo $snap || { usecount_decrement $vol $snap; return 1; }
	fi
}

# replication_cycle -
# called on a downstream host after each ddsnap listen cycle
function replication_cycle {
	[ $# -eq 1 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r sock=${SERVERS}/$vol
	local -r path=${VOLUMES}/$vol
	local -r holdfile=$path/source/hold
	local -r log=${LOGS}/$vol/source.log
	local next hold junk

	hold=$(cat $holdfile)

	if [[ -z $hold ]]; then
		hold=initial
		next=0
	else
		# FIXME TODO - can we assume next snapshot number? no not for chained replication
		next=$(( $hold + 1 ))
	fi

	log "replication cycle beginning - snapshot ($hold, $next)..." $log

	log "creating device..." $log
	create_snapshot $vol $next >> $log 2>&1

	log "setting holdfile to $next" $log
	echo $next > $holdfile

	# FIXME TODO - running sync is a workaround to make sure blocks are commited to disk
	log "running sync" $log
	sync >> $log 2>&1

	# FIXME TODO - we have to umount -l first, because umount always removes the topmost
	# filesystem :(, so we need to freeze access here
	if [[ $hold != "initial" ]]; then
		# NFS suspend
		echo "foo" > /proc/fs/nfsd/suspend 2>/dev/null
		log "umounting snapshot $hold " $log
		umount_device $vol $hold >> $log 2>&1
	fi

	log "mounting $vol($next)" $log
	mount_device $vol $next unqualified >> $log 2>&1

	if [[ $hold != "initial" ]]; then
		# NFS resume 
		cat /proc/fs/nfsd/suspend > /dev/null 2>&1
		log "removing snapshot $hold " $log
		usecount_decrement $vol $hold >> $log 2>&1
	fi

	log "cycle complete" $log

}

# nag_daemon
# daemon that runs in an endless loop, "nagging" upstream for replication
# data by writing "wakeup" to the target trigger to implement data "pull"
function nag_daemon {
	[ $# -eq 1 ] || { echo "$0: wrong argument count ($#: $@) in call: ${FUNCNAME[@]}"; exit 1; }
	local -r vol=$1
	local -r path=$VOLUMES/$vol
	local -r log=${LOGS}/$vol/nag.log
	local -r cron=${CRONS}/$vol
	local period
	local kind
	local host

	# FIXME TODO: It is a bad assumption that we use the short hostname
	# unless we enforece this.  Perhaps we should always use IPs?  This
	# would also elimiate ns failure or latency as an issue.
	local -r myhost=`hostname -s`

	host=$(cat $path/source/hostname)
	period=$(cat $path/source/period 2>/dev/null)

	[[ $period -gt 0 ]] || { log "no polling period specified for $vol, nothing to do" $log; return 0; }

	# daemonize (close stdin, stdout, stderr)
	exec 0</dev/null 1>/dev/null 2>/dev/null

	pid=""
	while true; do
		if [[ $pid == "" ]]; then
			pid=$!
			log "nag daemon starting for volume '$vol'" $log
		fi

		log "sending wakeup to $host:" $log
		run_remote $host "echo target $myhost > $VOLUMES/$vol/master/trigger" >> $log 2>&1
		sleep $period
	done &
}
function run_command {
	case $1 in
	define)
		case $2 in
		volume)
			[[ $# -ge 5 ]] && [[ $# -le 7 ]] || { echo "usage: $0 define volume <vol> <origin> <snapstore> [<metadev>] [noinit|nosnap]"; exit 2; }
			local -r vol=$3
			local -r origin=$4
			local -r snapstore=$5
			local metadev=""
			local noinit=""
			
			if [[ $# -eq 6 ]]; then
				if [[ $6 = "noinit" || $6 = "nosnap" ]]; then
					noinit=$6
				else
					metadev=$6
				fi
			elif [[ $# -eq 7 ]]; then
				$metadev=$6
				$noinit=$7
			fi

			verify_valid_volname $vol || { echo "$0: invalid volume name '$vol'"; exit 1; }
			verify_valid_device $origin || { echo "$0: invalid device '$origin'"; exit 1; }
			verify_valid_device $snapstore || { echo "$0: invalid device '$snapstore'"; exit 1; }
			[ -z $meta ] || verify_valid_device $metadev || { echo "$0: invalid device '$meta'"; exit 1; }

			if [[ $noinit = "noinit" ]]; then
				read -p "noinit: you must have initialized the device manually, continue? [y/N] " -t 30 \
					|| { echo "timeout."; exit 1; }

				[[ $REPLY = "y" ]] || { echo "aborted."; exit 1; }
				
				define_volume $vol $origin $snapstore $metadev || { echo "$0: define volume '$vol' failed"; exit 1; }
			else
				init_define_volume $vol $origin $snapstore $metadev || { echo "$0: init volume '$vol' failed"; exit 1; }

				echo "Successfully created and initialized volume '$vol'."

				if [[ $noinit = "nosnap" ]]; then
					echo "nosnap: no initial snapshot taken!"
					echo "This volume should only be used as a replication target, not source"
					exit 0
				fi

				create_snapshot $vol 0 || { echo "$0: error with initial snapshot"; exit 1; }
				echo 0 > $VOLUMES/$vol/zero

				echo "You can now create a filesystem on /dev/mapper/$vol"
			fi

			exit $? ;;
		target)
			[[ $# -eq 4 ]] || [[ $# -eq 5 ]] || { echo "usage: $0 define target <vol> <host>[:port] [period]"; exit 2; }
			local -r vol=$3
			local host=$4
			local period=$5
			local port=${host/*:/}

			# check to see if port was specified, if so, strip it off the host
			if [[ $host != $port ]]; then
				host=${host/:*/}
			else
				# otherwise use the default port
				port=$DEFAULT_PORT
			fi

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }
			verify_valid_host $host || { echo "$0: invalid host '$host'"; exit 1; }

			define_target $vol $host $port $period
			exit $? ;;
		master)
			[ $# -eq 5 ] || { echo "usage: $0 define master <vol> <kind> <count>"; exit 2; }
			local -r vol=$3
			local -r kind=$4
			local -r count=$5

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }
			find_in $kind ${KINDS[@]} || { echo "$0: unknown snapshot type '$kind'"; exit 1; }
			verify_valid_number $count || { echo "$0: bad snapshot count '$count'"; exit 1; }

			set_master $vol $kind $count
			exit $? ;;
		source)
			[[ $# -eq 4 ]] || [[ $# -eq 5 ]] || { echo "usage: $0 define source <vol> <host> [period]"; exit 2; }
			local -r vol=$3
			local -r host=$4
			local -r period=$5

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }
			verify_valid_host $host || { echo "$0: invalid host '$host'"; exit 1; }

			set_source $vol $host $period
			exit $? ;;
		*)
			echo "usage: $0 define volume|target|master|source"
			exit 2 ;;
		esac
		;;
	forget)
		case $2 in
		volume)
			[ $# -eq 3 ] || { echo "usage: $0 forget volume <vol>"; exit 2; }
			local -r vol=$3

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }

			forget_volume $vol
			exit $? ;;
		target)
			[ $# -eq 4 ] || { echo "usage: $0 forget target <vol> <host>"; exit 2; }
			local -r vol=$3
			local -r host=$4

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }
			verify_valid_host $host || { echo "$0: invalid host '$host'"; exit 1; }

			forget_target $vol $host
			exit $? ;;
		source)
			[ $# -eq 3 ] || { echo "usage: $0 forget source <vol>"; exit 2; }
			local -r vol=$3

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }

			forget_source $vol
			exit $? ;;
		*)
			echo "usage: $0 forget volume|target|source"
			exit 2 ;;
		esac
		;;
	start)
		case $2 in
		master)
			[ $# -eq 3 ] || { echo "usage: $0 start master <vol>"; exit 2; }
			local -r vol=$3

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }

			run_master $vol
			exit $? ;;
		target)
			[ $# -eq 4 ] || { echo "usage: $0 start target <vol> <host>"; exit 2; }
			local -r vol=$3
			local -r host=$4

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }
			verify_valid_host $host || { echo "$0: invalid host '$host'"; exit 1; }

			run_target $vol $host
			exit $? ;;
		source)
			[ $# -eq 3 ] || { echo "usage: $0 start source <vol>"; exit 2; }
			local -r vol=$3

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }

			nag_daemon $vol
			exit $? ;;
		*)
			echo "usage: $0 start master|target|source"
			exit 2 ;;
		esac
		;;
	stop)
		case $2 in
		master)
			[ $# -eq 3 ] || { echo "usage: $0 stop master <vol>"; exit 2; }
			local -r vol=$3

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }

			stop_master $vol
			exit $? ;;
		target)
			[ $# -eq 4 ] || { echo "usage: $0 stop target <vol> <host>"; exit 2; }
			local -r vol=$3
			local -r host=$4

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }
			verify_valid_host $host || { echo "$0: invalid host '$host'"; exit 1; }

			stop_target $vol $host || exit 1
			exit $? ;;
		source)
			[ $# -eq 3 ] || { echo "usage: $0 stop source <vol>"; exit 2; }
			local -r vol=$3

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }

			stop_nag $vol
			exit $? ;;
		*)
			echo "usage: $0 stop master|target|source"
			exit 2 ;;
		esac
		;;
	snapshot)
		[ $# -eq 3 ] || { echo "usage: $0 snapshot <vol> <kind>"; exit 2; }
		local -r vol=$2
		local -r kind=$3

		verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }
		find_in $kind ${KINDS[@]} || { echo "$0: unknown snapshot type '$kind'"; exit 1; }

		trigger_snapshot $vol $kind
		exit $?
		;;
	replicate)
		[[ $# -eq 3 ]] || [[ $# -eq 4 ]] || { echo "usage: $0 replicate <vol> <host> [snap]"; exit 2; }
		local -r vol=$2
		local -r host=$3
		local -r snap=$4

		verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }
		verify_existing_target $vol $host || { echo "$0: host '$host' is not a target for volume '$vol'"; exit 1; }
		[ -z $snap ] || verify_existing_snap $vol $snap || { echo "$0: invalid snapshot '$snap' for volume '$vol'"; exit 1; }

		# <snap> is optional and a new snapshot is taken if omitted
		trigger_replication $vol $host $snap
		exit $?
		;;
	status)
		[ $# -lt 4 ] || { echo "usage: $0 status [-f] [<vol> [<snap>]]"; exit 2; }

		# !!! zero or one arguments means to call tree for now
		if [ $# -lt 3 ]; then
			local -r opt=$2
			local vol

			# for debugging
			#tree -Fx --noreport $opt $VOLUMES
			pushd $VOLUMES >/dev/null
			[[ `ls | wc -l` -gt 0 ]] && for vol in *; do
				echo VOLUME $vol:
				if [ -e $SERVERS/$vol ]; then
					ddsnap status $SERVERS/$vol && echo Status: running || echo Status: failed
				else
					echo Status: not running
				fi
				echo "Configuration:"
				tree -Fx --noreport $opt $VOLUMES/$vol
				echo
			done 2> /dev/null
			popd >/dev/null
			echo RUN STATUS:
			tree -Fx --noreport $opt $RUNPATH
			exit $?
		else
			local -r vol=$2
			local -r snap=$3
			local -r sock=${SERVERS}/$vol

			verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }
			[ -z $snap ] || verify_existing_snap $vol $snap || { echo "$0: invalid snapshot '$snap' for volume '$vol'"; exit 1; }

			ddsnap status $sock $snap
			exit $?
		fi
		;;
	receive)
		# called via upstream host's ssh command to start/stop listen
		[ $# -eq 4 ] || { echo "usage: $0 receive <vol> <port> {start|done}"; exit 2; }
		local -r vol=$2
		local -r port=$3
		local -r startstop=$4
		local -r holdfile=$VOLUMES/$vol/source/hold
		local rpid
		local snap

		verify_managed_vol $vol || { echo "$0: volume '$vol' is not a managed volume"; exit 1; }

		case $startstop in
		start)
			# !!! FIXME TODO if the hold file doesn't exist
			# assume we are initializing replication at snapshot 0
			snap=$(cat $holdfile 2>/dev/null) || snap=0

			# start the listen daemon
			# FIXME TODO - for now we listen on 0.0.0.0 and we don't check where
			# the request came from, in the future, to avoid doing something
			# wrong, such as replicatin from 2 hosts, check the $SSH_CLIENT
			# environment variable

			# kill listen first in case it is already listening (previous replication interrupted)
			pkill -f "ddsnap delta listen /dev/mapper/$vol 0.0.0.0:$port"

			rpid=$(ddsnap delta listen /dev/mapper/$vol 0.0.0.0:$port)

			# if successful, ouput should be "pid = <pid>"
			rpid=${rpid/pid = /}

			# if successful, send the hold snapid back to the caller
			[[ $rpid -gt 1 ]] && echo $snap
			exit $? ;;
		done)
			pkill -f "ddsnap delta listen /dev/mapper/$vol 0.0.0.0:$port"
			replication_cycle $vol

			exit $? ;;
		esac
		;;
	esac

	[ $# -gt 0 ] && echo "Error in command: $@"
	echo "Usage: $0 {define|forget|start|stop|snapshot|replicate|status} [<subarguments>...]"
	exit 2
}


[[ -d $VOLUMES ]] || { echo "$0: cannot find zumastor database in '$VOLUMES'"; exit 1; }
[[ $1 == "status" ]] || [[ -e $RUNFILE ]] || { echo "$0: zumastor not running, start with '/etc/init.d/zumastor start' first"; exit 1; }
run_command "$@"

